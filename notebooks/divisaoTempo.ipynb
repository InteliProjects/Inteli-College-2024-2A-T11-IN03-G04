{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de e clusterização de tempo por quantidade de PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Esse é um arquivo python notebook (.ipynb) para uma compreensão de dados para a parceria com a Compass. São utilizadas as bibliotecas pandas, numpy e matplotlib. É feito o carregamento e concatenação simultânea de cada tabela (.csv) contendo de dados dos meses. É utilizada uma função para descrever a estatística descritiva da coluna \"datetime\" da tabela. Em seguida foram criados gráficos para diferentes análises da coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Carregamento e concatenação de todas tabelas disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pnd.read_csv('month_2.csv')# Concatena diferentes tabelas com cada mês (dados)\n",
    "# Em seguida salva todos os dados em um único DataFrame chamado df\n",
    "listas = ['month_2.csv', 'month_3.csv', 'month_4.csv', 'month_5.csv', 'month_6.csv']\n",
    "df = []\n",
    "for arquivo in listas:\n",
    "    df += [pnd.read_csv(arquivo)]\n",
    "\n",
    "# Concatena todos os dataframes em um único dataframe chamado df\n",
    "df = pnd.concat(df)\n",
    "\n",
    "# Chama o dataframe contido na variável chamada df\n",
    "df.sort_values(by='datetime', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré processamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Compreensão de dados da coluna datetime para verificar se a análise descritiva possui alguma incoerência que precisa ser corrigida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa linha de código converte a coluna 'datetime' do DataFrame df para o tipo datetime usando a função to_datetime da biblioteca pandas (pnd).\n",
    "df['datetime'] = pnd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza as análises descritivas da coluna datetime\n",
    "df['datetime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Lê os dados cadastrais e forma um novo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega e salva dadosCadastrais como dadosCadastrais\n",
    "dadosCadastrais = pnd.read_csv('informacao_cadastral.csv')\n",
    "\n",
    "# Chama o dataframe contido na variável dadoCadastrais\n",
    "dadosCadastrais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria uma função extendida de descrever (estatísticas descritivas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função extendida de descrever (estatísticas descritivas)\n",
    "def describeExtended(data):\n",
    "    description = data.describe()\n",
    "\n",
    "    # Adiciona a mediana, variância e moda para a função describe\t\n",
    "    description.loc['var'] = data.var()\n",
    "    description.loc['median'] = data.median()\n",
    "    description.loc['mode'] = data.mode().iloc[0]\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva pulseCount\n",
    "print(describeExtended(df.pulseCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Nessa seção são feitas algumas alterações básicas e geradas uma nova dataframe a partir do que foi filtrado, organizado (ordenar por data), e calculadas as diferenças entre valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra os usuários que estão consumindo gás (operacionais) e por seu código de cliente\n",
    "usuariosUnicos = dadosCadastrais[dadosCadastrais.situacao == 'CONSUMINDO GÁS']['clientCode'].unique() \n",
    "# Organiza os dados dos usuários filtrados pela data\n",
    "mesFiltrado = df[df['clientCode'].isin(usuariosUnicos)].sort_values(by='datetime') \n",
    "# Filtra meterSN diferente de '>N<A'\n",
    "mesFiltrado = mesFiltrado[mesFiltrado['meterSN'] != '>N<A']\n",
    "# Cria uma nova variável mesFiltrado, agrupa por meterSN e clientCode e seleciona a primeira linha\n",
    "resultado = mesFiltrado.groupby(['meterSN', 'clientCode']).first() \n",
    "# Seleciona a coluna pulseCount\n",
    "resultado = resultado[['pulseCount']] \n",
    "# Cria um novo dataframe com a coluna pulseCountInicial\n",
    "final = pnd.DataFrame({'pulseCountInicial': resultado.pulseCount}) \n",
    "# Junta os dataframes\n",
    "merged_df = pnd.merge(df, final, on=['meterSN', 'clientCode'], how='left') \n",
    "# Calcula a diferença entre pulseCount e pulseCountInicial\n",
    "merged_df['pulseCount'] = merged_df['pulseCount'] - merged_df['pulseCountInicial'] \n",
    "#Mostra o dataframe 'merged_df'\n",
    "merged_df.sort_values(by='datetime', inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterização do horário de cada Pulse Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garante que a coluna 'datetime' esteja no formato datetime\n",
    "merged_df['datetime'] = pnd.to_datetime(merged_df['datetime'])\n",
    "\n",
    "# Extrai a hora da coluna `datetime`\n",
    "merged_df['hour'] = merged_df['datetime'].dt.hour\n",
    "\n",
    "# Cria a coluna `period` com base na hora\n",
    "def get_period(hour):\n",
    "  if 0 <= hour <= 6:\n",
    "    return 'madrugada'\n",
    "  elif 7 <= hour <= 12:\n",
    "    return 'manhã'\n",
    "  elif 13 <= hour <= 18:\n",
    "    return 'tarde'\n",
    "  else:\n",
    "    return 'noite'\n",
    "\n",
    "merged_df['period'] = merged_df['hour'].apply(get_period)\n",
    "\n",
    "# Imprime os primeiros 5 registros para verificar\n",
    "print(merged_df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma uma lista com todos os números de Pulse Count por hora\n",
    "merged_df['hour'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Ajuda a visualizar como está a distribuição de registro de PC ao longo de um dia inteiro pegando informações de todas as tabelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Gráfico de barras que apresenta a quantidade de total, ou seja, pega todas as medições de pulse count que aconteceram em cada hora do dia e soma juntando tudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega a lista acima e transforma em um gráfico de barras\n",
    "ax = merged_df['hour'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Pega os horários do gráfico anterior e clusteriza todos em 4 seções, madrugada, manhã, tarde e noite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df['period'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Com base nos gráficos acima, podemos chegar a uma conclusão central: embora os usuários utilizem gás em horários \"comuns\", como 06:00 (horário em que os brasileiros costumam acordar para ir trabalhar), 12:00 (horário de almoço) e 20:00 (horário comum para o jantar ou para tomar banho), as medições ocorrem, de fato, após um período de tempo, o que resulta em uma distribuição mais uniforme ao longo das horas. No entanto, ao analisarmos o período da manhã, podemos observar uma distribuição \"anormal\" ao longo do horário, que difere dos demais, principalmente às 09:00, quando o pico de registro de consumo é atingido. Isso pode nos levar a duas questões: os registros de PC são realizados com atraso, mas sem um horário exato de delay; e a temperatura mais baixa pela manhã poderia levar a um maior uso de aquecedores a gás, resultando nesse pico de consumo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
