{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Compreensão dos Dados\n",
    "\n",
    "#### 4.2.1. Exploração de dados\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;A exploração de dados é uma etapa essencial na construção de modelos preditivos, pois permite compreender as características intrínsecas do conjunto de dados e identificar padrões relevantes para as análises subsequentes. Nessa fase, são apresentadas as estatísticas descritivas básicas de cada coluna, possibilitando uma visão inicial sobre a distribuição dos dados. Além disso, é fundamental distinguir entre colunas numéricas e categóricas, já que essa classificação orienta a escolha das técnicas de visualização e modelagem apropriadas. A exploração também inclui a criação de gráficos que permitem visualizar as relações entre as colunas selecionadas, facilitando a identificação de correlações, tendências e possíveis outliers que possam influenciar o desempenho dos modelos preditivos.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Nesse processo de exploração dos dados, foram desenvolvidas algumas tabelas e gráficos apresentados a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`São utilizadas as bibliotecas pandas, numpy, matplotlib e seaborn. É feito o carregamento e concatenação simultânea de cada tabela (.csv) contendo de dados dos meses. É utilizada uma função para descrever a estatística descritiva de diferentes colunas da tabela. Em seguida foram criados gráficos para diferentes análises da tabela.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega biblioteca pandas\n",
    "import pandas as pnd\n",
    "# Carrega biblioteca numpy\n",
    "import numpy as np\n",
    "# Carrega biblioteca matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Carrega biblioteca seaborn\n",
    "import seaborn as sb\n",
    "# Carrega biblioteca sklearn KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "# Carrega biblioteca sklearn LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Carregamento e Concatenação de Todas Tabelas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena diferentes tabelas com cada mês (dados)\n",
    "# Em seguida salva todos os dados em um único DataFrame chamado df\n",
    "listas = ['month_2.csv', 'month_3.csv', 'month_4.csv', 'month_5.csv', 'month_6.csv']\n",
    "df = []\n",
    "for arquivo in listas:\n",
    "    df += [pnd.read_csv(arquivo)]\n",
    "\n",
    "# Concatena todos os dataframes em um único dataframe chamado df\n",
    "df = pnd.concat(df)\n",
    "\n",
    "# Chama o dataframe contido na variável chamada df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Carrega Dados Cadastrais`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega e salva dadosCadastrais como dadosCadastrais\n",
    "dadosCadastrais = pnd.read_csv('informacao_cadastral.csv')\n",
    "\n",
    "# Chama o dataframe contido na variável dadoCadastrais\n",
    "dadosCadastrais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Normalização Coluna 'cidade'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega diferentes possibilidades para a coluna 'cidade'\n",
    "# Antes da normalização\n",
    "dadosCadastrais['cidade'].unique()\n",
    "\n",
    "# Substituindo \"GRAVATAI\" por \"GRAVATAÍ\" na coluna \"cidade\"\n",
    "dadosCadastrais['cidade'] = dadosCadastrais['cidade'].replace('GRAVATAI', 'GRAVATAÍ')\n",
    "\n",
    "# Substituindo \"SAO LEOPOLDO\" por \"SÃO LEOPOLDO\" na coluna \"cidade\"\n",
    "dadosCadastrais['cidade'] = dadosCadastrais['cidade'].replace('SAO LEOPOLDO', 'SÃO LEOPOLDO')\n",
    "\n",
    "# Verificando entradas na coluna \"cidade\"\n",
    "dadosCadastrais['cidade'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Função para a realização da análise descritiva`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função extendida de descrever (estatísticas descritivas)\n",
    "def describeExtended(data):\n",
    "    description = data.describe()\n",
    "\n",
    "    # Adiciona a mediana, variância e moda para a função describe\t\n",
    "    description.loc['var'] = data.var()\n",
    "    description.loc['median'] = data.median()\n",
    "    description.loc['mode'] = data.mode().iloc[0]\n",
    "    return description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Classificação de tipo de dados entre Numérico e Categórico`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição Tabela X:** A tabela apresenta a definição do tipo de dado para cada coluna do conjunto analisado, distinguindo entre colunas categóricas e numéricas. A maioria das colunas é composta por dados numéricos, refletindo a natureza quantitativa das medições realizadas, como consumo de gás (pulseCount) e valores de identificação (clientCode). Essa predominância de dados numéricos direciona as análises , permitindo a aplicação de diversas técnicas estatísticas e de visualização para explorar as relações entre essas variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" width=\"100%\">\n",
    "<sub>Tabela X - Classificação de tipo de dados entre Numérico e Categórico</sub>\n",
    "</div><br>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Coluna | Numérica/Categórica | Label Encoding (Somente Categóricas) |\n",
    "| --------- | ---------------| -------------------------------------|\n",
    "| clientCode | Numérico | - |\n",
    "| clientIndex | Categórico | 0, 1, 2, 3, 4 | \n",
    "| meterIndex | Numérico | - |   \n",
    "| initialIndex | Numérico | - |\n",
    "| pulseCount | Numérico | - |\n",
    "| gain | Numérico (constante) | - |\n",
    "| datetime | Numérico | - | \n",
    "| meterSN | Numérico | - |\n",
    "| inputType | Categórico | 0, 1, 2, 3, 4, 5, 6, 7, 8 |\n",
    "| model | Categórico | 0, 1 |\n",
    "| rssi | Numérico | - |\n",
    "| gatewayGeoLocation.alt | Numérico | - |\n",
    "| gatewayGeoLocation.lat | Numérico | - |\n",
    "| gatewayGeoLocation.long | Numérico | - |\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<sup>Fonte: Material produzido pelos autores (2024)\n",
    "</sup>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LabelEnconder Dataframe Variáveis Categóricas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicação do \"LabelEncoder\" em valores categóricos, conforme a tabela anterior. Os valores das colunas \"clientIndex\", \"inputType\" e \"model\" são codificados em números começando de 0 até o número de categorias distintas em cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar LabelEncoder\n",
    "label_encoder_clientIndex = LabelEncoder()\n",
    "label_encoder_inputType = LabelEncoder()\n",
    "label_encoder_model = LabelEncoder()\n",
    "\n",
    "# Faz fit, transforma as colunas, e substitui os valores originais pelos codificados por LabelEncoder\n",
    "df['clientIndex'] = label_encoder_clientIndex.fit_transform(df['clientIndex'])\n",
    "df['inputType'] = label_encoder_inputType.fit_transform(df['inputType'])\n",
    "df['model'] = label_encoder_model.fit_transform(df['model'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estatística descritiva referente ao pulseCount`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição Tabela X:** O campo \"pulseCount\" é referente ao número de pulsos registrados por um medidor de consumo de gás. Cada pulso corresponde a uma unidade de volume de gás consumido, medida pelo medidor instalado no cliente. Esse valor é importante para calcular o consumo total de gás de um cliente em um determinado período, permitindo a análise do uso de gás e a identificação de padrões de consumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva pulseCount\n",
    "print(describeExtended(df.pulseCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" width=\"100%\">\n",
    "<sub>Tabela X - Estatística descritiva referente ao pulseCount</sub>\n",
    "</div><br>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "\n",
    "\n",
    "| Estatística | Valor | \n",
    "| --------- | ---------------|\n",
    "| Média | 3.696606e+03 |\n",
    "| Mediana | 3.780000e+02 |\n",
    "| Moda | 0.000000e+00 |   \n",
    "| Variância | 3.608793e+08 |\n",
    "| Desvio Padrão | 1.899682e+04 |\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<sup>Fonte: Material produzido pelos autores (2024)\n",
    "</sup>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estatística descritiva referente ao meterIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição Tabela X:** O campo \"meterIndex\" representa a leitura atual do medidor de gás de um cliente. Esse valor indica a quantidade total de gás consumido até o momento da leitura. Ele é acumulativo, ou seja, a cada nova leitura o \"meterIndex\" reflete o consumo total registrado desde a instalação do medidor. Esse dado é necessário para calcular o consumo de gás ao longo do tempo e para gerar faturas com base no uso real do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva meterIndex\n",
    "print(describeExtended(df.meterIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" width=\"100%\">\n",
    "<sub>Tabela X - Estatística descritiva referente ao meterIndex</sub>\n",
    "</div><br>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Estatística | Valor | \n",
    "| --------- | ---------------|\n",
    "| Média | 1.387267e+03 |\n",
    "| Mediana | 3.509000e+01 |\n",
    "| Moda | 6.400000e-01 |   \n",
    "| Variância | 4.596080e+08 |\n",
    "| Desvio Padrão | 2.143847e+04 |\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<sup>Fonte: Material produzido pelos autores (2024)\n",
    "</sup>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estatística descritiva referente ao initialIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição Tabela X:** O campo \"initialIndex\" representa o valor de leitura do medidor de gás no momento em que o sensor foi instalado. Esse valor marca o ponto de partida para todas as medições posteriores, servindo como a referência inicial para calcular o consumo total de gás do cliente a partir da data de instalação. Ele é utilizado para determinar o consumo acumulado desde o início do funcionamento do equipamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva initialIndex\n",
    "print(describeExtended(df.initialIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" width=\"100%\">\n",
    "<sub>Tabela X - Estatística descritiva referente ao initialIndex</sub>\n",
    "</div><br>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Estatística | Valor | \n",
    "| --------- | ---------------|\n",
    "| Média | 1.324937e+03 |\n",
    "| Mediana | 2.873000e+00 |\n",
    "| Moda | 0.000000e+00 |   \n",
    "| Variância | 4.562067e+08 |\n",
    "| Desvio Padrão | 2.135900e+04 |\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<sup>Fonte: Material produzido pelos autores (2024)\n",
    "</sup>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gráfico de consumo incomum de um cliente`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição do gráfico X:** Este gráfico mostra o comportamento do consumo de gás, representado pela variável \"pulseCount\", ao longo do tempo \"datetime\". A linha azul representa a leitura cumulativa do consumo, que aumenta progressivamente ao longo do tempo até atingir um pico, seguido por uma queda abrupta e um novo aumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Especifica o cliente que possui anomalia e cria um gráfico de linha da anomalia\n",
    "clienteAnomalia = df[df['clientCode'].str.contains(\"e3322382e75c0d0a8e95f80af703932bd3c38f940aa59a\")].sort_values(by='datetime')\n",
    "sb.lineplot(data=clienteAnomalia, x='datetime', y='pulseCount', hue='clientCode', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gráfico Scatterplot 'pulseCount', 'meterIndex' Sem Processamento`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição do gráfico X:** O gráfico de dispersão apresenta a relação entre o \"pulseCount\" (contagem de pulsos) e o \"meterIndex\" (índice do medidor) para diferentes \"meterSN\" (número de série do medidor). Cada ponto representa a última leitura registrada para um determinado medidor, identificada pelo \"meterSN\", e a cor dos pontos varia conforme o medidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um gráfico de dispersão, sem a normalização da coluna pulseCount\n",
    "ultimo_df_sem_proc = df.groupby(['meterSN', 'clientCode']).last()\n",
    "sb.scatterplot(data=ultimo_df_sem_proc, x='pulseCount', y='meterIndex', hue='meterSN', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Análise:** A maioria dos dados está concentrada em valores baixos de \"pulseCount\" e \"meterIndex\", indicando que a maioria dos medidores possui contagens de pulsos e índices relativamente pequenos. No entanto, alguns pontos outliers são observados, especialmente em \"meterIndex\", sugerindo que certos medidores tem longo tempo de uso ou apresentam clientes que consomem muito mais que a média."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gráfico boxplot 'pulseCount' Sem Processamento`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Descrição do gráfico X:** Este gráfico é um boxplot que mostra a distribuição da frequência de pulsos \"pulseCount\" para o conjunto de dados analisado. Este tipo de gráfico é útil para identificar a dispersão dos dados e detectar a presença de outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficoFinal = df.groupby(['meterSN', 'clientCode']).last()\n",
    "# Boxplot da frequência de pulsos\n",
    "ax = sb.boxplot(x= 'pulseCount', data=graficoFinal, orient='h')\n",
    "ax.figure.set_size_inches(12,6)\n",
    "ax.set_title('Boxplot da frequência de pulsos', fontsize=18)\n",
    "ax.set_xlabel('Consumo', fontsize=14)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Análise:** No boxplot, a maioria dos dados de consumo está concentrada próxima ao valor mínimo, com uma longa cauda de outliers estendendo-se para valores mais altos. Isso indica que a maioria dos clientes tem um consumo relativamente baixo, enquanto alguns poucos registros apresentam consumos excepcionalmente elevados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Pré-processamento dos dados\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;O pré-processamento dos dados é uma etapa fundamental para garantir a qualidade e a integridade das informações utilizadas nos modelos preditivos. Nessa fase, foram realizadas ações de limpeza e transformação das colunas do conjunto de dados. A limpeza incluiu o tratamento de valores ausentes (missing values), onde foram aplicadas técnicas como exclusão de registros incompletos, além da identificação e remoção de outliers que poderiam distorcer as análises.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;No contexto de transformação dos dados, as colunas numéricas foram normalizadas para garantir que diferentes escalas de valores não impactassem os resultados. Durante essa análise, outliers específicos foram identificados em determinadas colunas, e as correções apropriadas, como a exclusão de registros anômalos, foram aplicadas para minimizar seu impacto nos modelos. Todos esses processos e análises serão detalhados a seguir.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;No projeto, a equipe iniciou o pré-processamento dos dados filtrando os clientes com base no consumo ativo de gás. Essa etapa começou com o acesso à tabela de informações cadastrais, \"informacao_cadastral.csv\", onde todos os usuários foram filtrados de acordo com sua situação atual: \"CONSUMINDO GÁS\", \"CONTRATADO\" ou \"DESATIVADO\". A partir desse filtro, foram removidos da tabela principal todos os registros que não correspondiam a consumidores ativos, ou seja, aqueles que não estavam na situação \"CONSUMINDO GÁS\". Essa ação contribuiu para a redução de dados nulos no banco de dados, eliminando informações irrelevantes para a análise subsequente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra os usuários que estão consumindo gás (operacionais) e por seu código de cliente\n",
    "usuariosUnicos = dadosCadastrais[dadosCadastrais.situacao == 'CONSUMINDO GÁS']['clientCode'].unique() \n",
    "# Organiza os dados dos usuários filtrados pela data\n",
    "mesFiltrado = df[df['clientCode'].isin(usuariosUnicos)].sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Em seguida, foi aplicado um filtro na tabela principal com base na data, utilizando a coluna \"datetime\". Durante essa fase, os registros na coluna \"MeterSN\" que apresentavam o valor \">N<A\" foram excluídos, garantindo a integridade dos dados restantes. Após essa exclusão, a equipe selecionou todos os contadores de pulsos iniciais na coluna \"pulsecount\" para cada cliente. Esse processo envolveu o ordenamento dos registros tanto pela coluna \"clientCode\" quanto por \"MeterSN\", resultando na criação de uma nova tabela chamada \"final\", que armazenava os valores iniciais de contagem de pulsos para cada cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra meterSN diferente de '>N<A'\n",
    "mesFiltrado = mesFiltrado[mesFiltrado['meterSN'] != '>N<A']\n",
    "# Cria uma nova variável mesFiltrado, agrupa por meterSN e clientCode e seleciona a primeira linha\n",
    "resultado = mesFiltrado.groupby(['meterSN', 'clientCode']).first() \n",
    "# Seleciona a coluna pulseCount\n",
    "resultado = resultado[['pulseCount']] \n",
    "# Cria um novo dataframe com a coluna pulseCountInicial\n",
    "final = pnd.DataFrame({'pulseCountInicial': resultado.pulseCount}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Para aprimorar a análise, a equipe realizou um merge da tabela \"final\" com a tabela original de dados, incorporando a coluna de contagem inicial de pulsos ao conjunto de dados principal. Com essa integração concluída, foi realizada uma normalização dos dados: subtraiu-se o valor de todos os pulse counts momentâneos pelo valor inicial correspondente. Essa abordagem garantiu que a contagem de pulsos para todos os clientes começasse do zero no período analisado, padronizando os dados para uma análise comparativa mais precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junta os dataframes\n",
    "merged_df = pnd.merge(df, final, on=['meterSN', 'clientCode'], how='left') \n",
    "# Calcula a diferença entre pulseCount e pulseCountInicial\n",
    "merged_df['pulseCount'] = merged_df['pulseCount'] - merged_df['pulseCountInicial'] \n",
    "#Mostra o dataframe 'merged_df'\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Além disso, foram identificados e excluídos outliers que se desviavam significativamente do padrão geral dos dados. Esses outliers foram detectados utilizando a métrica de dois desvios padrões acima da média, ou seja, valores que se encontravam muito fora da curva de normalidade e ultrapassavam o esperado para o consumo de gás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df['pulseCount'] > (merged_df.pulseCount.mean() - (2*merged_df.pulseCount.std()))]\n",
    "merged_df = merged_df[merged_df['pulseCount'] < (merged_df.pulseCount.mean() + (2*merged_df.pulseCount.std()))]\n",
    "\n",
    "merged_df.loc[merged_df.pulseCount.idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A presença desses outliers extremos impactava negativamente o desempenho do modelo preditivo, pois introduzia uma distorção significativa nos cálculos. Valores muito elevados podem desviar as previsões, fazendo com que o modelo aprenda padrões irreais ou seja influenciado por dados que não refletem o comportamento esperado dos clientes. Ao remover esses pontos anômalos, o modelo se torna mais robusto e capaz de capturar de forma mais precisa as tendências dos dados reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Também foram identificados comportamentos inconsistentes nos dados após a normalização. Especificamente, foi observada a presença de valores negativos na coluna \"pulseCounts\", indicando que, em algum momento do período analisado, houve uma drástica diminuição na contagem de pulsos. Esse comportamento é inconsistente e não esperado, já que a contagem de pulsos deve ser sempre positiva e acumulativa, somando-se ao valor anterior. Esses dados serão tratados posteriormente nas hipóteses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Especifica o cliente que possui anomalia e cria um gráfico de linha da anomalia\n",
    "clienteAnomalia = merged_df[merged_df['clientCode'].str.contains(\"e3322382e75c0d0a8e95f80af703932bd3c38f940aa59a\")].sort_values(by='datetime')\n",
    "sb.lineplot(data=clienteAnomalia, x='datetime', y='pulseCount', hue='clientCode', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Hipóteses\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Nesta seção, serão apresentadas as hipóteses levantadas pela equipe para explicar comportamentos fora do esperado, mesmo após as etapas de limpeza e transformação. O objetivo é entender melhor os possíveis motivos por trás das anomalias identificadas, e como essas hipóteses guiaram as correções aplicadas para melhorar a qualidade dos dados e a precisão do modelo preditivo.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Ao ajustar todos os valores de contagem de pulsos para partir de um ponto inicial zero, a equipe identificou uma problemática significativa: em vários casos, houve uma queda brusca e inesperada na contagem de pulsos, que fazia com que os valores retornassem números negativos. Esse comportamento anômalo, detalhado anteriormente na seção de pré-processamento, levantou a necessidade de formular hipóteses que pudessem explicar tal ocorrência.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Intervenção Humana:** Uma das hipóteses sugeridas para explicar essa queda abrupta é a possibilidade de interferência humana no funcionamento do medidor de gás. Essa interferência poderia ter várias formas, como danos intencionais ou acidentais ao aparelho de medição, adulteração para manipular os dados de consumo ou até mesmo a realização de manutenção que, de alguma forma, zerou a contagem de pulsos. Essas ações poderiam resultar em uma reinicialização do medidor, fazendo com que o contador retornasse a zero, independentemente do valor acumulado anteriormente, e mostrassem numeros negativos após a normalização feita. Tal hipótese é preocupante, pois implica em possíveis fraudes ou erros operacionais que podem comprometer a precisão dos dados coletados.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Problema com o Medidor:** Outra hipótese considerada é a ocorrência de falhas técnicas no medidor de pulsos. Essas falhas poderiam se originar de problemas no hardware do dispositivo, como defeitos na sua estrutura física ou desgaste de componentes, que resultariam na perda de dados e reinicialização do contador. No entanto, o problema também poderia estar no software responsável pela operação do medidor, onde um bug, uma pane no sistema ou erro de programação poderia causar a perda dos dados armazenados e o retorno à contagem zero. Essa hipótese leva a um questionamento se há uma avaliação rigorosa e periódica dos equipamentos e sistemas utilizados para garantir que eles estejam funcionando corretamente.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Em outra situação analisada, a equipe identificou um comportamento anômalo na variação de pulsos, onde foram observadas variações negativas nos dados. Isso indica que a contagem de pulsos regrediu numericamente em relação ao valor registrado anteriormente, um fenômeno que, logicamente, não deveria ocorrer, pois a contagem de pulsos deve sempre ser acumulativa. Esse comportamento anômalo foi especialmente notado em medições realizadas em intervalos de tempo muito curtos, de apenas alguns minutos, diferindo do intervalo padrão, que geralmente é de cerca de uma hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega um cliente específico em que a analise foi detectada\n",
    "clienteAnalise = merged_df[merged_df['clientCode'].str.contains('345b8ca6318576583eb9cb2a1743e725abfdbfcba87f34')]\n",
    "clienteAnalise.sort_values(by='datetime', inplace=True)\n",
    "#Calcula a variação do pulseCount, cria uma coluna nova com esse valor\n",
    "clienteAnalise['variacaoPulseCount'] = clienteAnalise['pulseCount'].diff()\n",
    "#A primeira linha tem a variação nula, conserta com o valor do pulseCount inicial\n",
    "clienteAnalise['variacaoPulseCount'].fillna(clienteAnalise['pulseCount'], inplace=True)\n",
    "clienteAnalise.reset_index(drop=True, inplace=True)\n",
    "#Cria um gráfico de linha com a variação do pulseCount\n",
    "sb.lineplot(data=clienteAnalise, x='datetime', y='variacaoPulseCount', legend=False)\n",
    "#Chama as colunas antes e depois da anomalia\n",
    "clienteAnalise.loc[clienteAnalise.variacaoPulseCount.idxmin()-1:clienteAnalise.variacaoPulseCount.idxmin()+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Erro na Transmissão de Dados (Sinais Sendo Enviados/Recebidos em Ordem Incorreta):** Uma hipótese que pode explicar essas variações negativas é a ocorrência de erros na transmissão dos dados entre o medidor de pulsos e o sistema central de coleta. Esses erros podem ocorrer quando os sinais são enviados ou recebidos fora de ordem, fazendo com que as leituras mais recentes sejam registradas antes das leituras anteriores. Por exemplo, se uma medição posterior é transmitida e registrada antes de uma medição anterior devido a um atraso ou interferência no sinal, isso pode criar a ilusão de uma variação negativa na contagem de pulsos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Por motivos de estruturação e necessidade, repetimos parte deste código anteriormente, mas, neste caso, ele gera o gráfico para uma determinada hipótese de vazamento de gás. Também foram calculados a média e o desvio padrão da diferença de pulseCounts. Esses valores foram utilizados para encontrar clientes com diferenças maiores que 3 desvios padrões e identificar uma anomalia, cujo gráfico foi utilizado como exemplo. (Código para \"Gráfico Anomalia Pico Positivo pulseCount\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra os usuários que estão consumindo gás (operacionais) e por seu código de cliente\n",
    "usuariosUnicos = dadosCadastrais[dadosCadastrais.situacao == 'CONSUMINDO GÁS']['clientCode'].unique() \n",
    "# Organiza os dados dos usuários filtrados pela data\n",
    "mesFiltrado = df[df['clientCode'].isin(usuariosUnicos)].sort_values(by='datetime') \n",
    "# Filtra meterSN diferente de '>N<A'\n",
    "mesFiltrado = mesFiltrado[mesFiltrado['meterSN'] != '>N<A']\n",
    "# Cria uma nova variável mesFiltrado, agrupa por meterSN e clientCode e seleciona a primeira linha\n",
    "resultado = mesFiltrado.groupby(['meterSN', 'clientCode']).first() \n",
    "# Seleciona a coluna pulseCount\n",
    "resultado = resultado[['pulseCount']] \n",
    "# Cria um novo dataframe com a coluna pulseCountInicial\n",
    "final = pnd.DataFrame({'pulseCountInicial': resultado.pulseCount}) \n",
    "# Junta os dataframes\n",
    "df = pnd.merge(df, final, on=['meterSN', 'clientCode'], how='left') \n",
    "# Calcula a diferença entre pulseCount e pulseCountInicial\n",
    "df['pulseCount'] = df['pulseCount'] - df['pulseCountInicial'] \n",
    "df = df[['clientCode', 'pulseCount', 'meterSN', 'gain', 'datetime']].sort_values(by='datetime')\n",
    "df['pulseCountCorrigido'] = df['pulseCount'] * df['gain']\n",
    "df['diffpulseCount']= df.groupby(['meterSN', 'clientCode'])['pulseCount'].diff()\n",
    "df['mediacliente'] = df.groupby(['meterSN', 'clientCode'])['diffpulseCount'].transform('mean')\n",
    "df['desviopadrao'] = df.groupby(['meterSN', 'clientCode'])['diffpulseCount'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['diffpulseCount'] > df['mediacliente'] + 3*df['desviopadrao']]\n",
    "\n",
    "clientegrafico = df[df['clientCode'].str.contains('3ba067469805939235e0d4e553501c05c8ad33a79ad217')].sort_values(by='datetime')\n",
    "\n",
    "plt.plot(clientegrafico['datetime'], clientegrafico['pulseCount'])\n",
    "plt.xlabel('datetime')\n",
    "plt.ylabel('pulseCount')\n",
    "plt.title('Gráfico Anomalia Pico Positivo pulseCount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;**Vazamento de gás:** Uma hipótese para explicar picos abruptos e elevados no consumo de gás é a ocorrência de vazamentos. Isso pode ser observado no 'Gráfico Anomalia Pico Positivo'. O aumento no consumo pode estar relacionado a problemas no encanamento, o que resulta em leituras mais altas nos medidores. Esses vazamentos, possivelmente localizados em áreas de difícil acesso ou não visíveis, podem ocorrer tanto em ambientes internos quanto externos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Essas hipóteses levantadas fornecem uma base importante para futuras investigações, destacando a complexidade dos desafios enfrentados. Embora ainda não tenham sido implementadas intervenções concretas, essas reflexões abrem caminho para um entendimento mais profundo das anomalias observadas e servem como um guia para possíveis ações corretivas posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Preparação dos Dados e Modelagem\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Nesta seção, será apresentada a preparação dos dados para a primeira modelagem com o objetivo de solucionar o problema disposto na detecção de anomalias. Além disso serão apresentados o tipo do modelo escolhido, a definição de features escolhidas para compor o modelo, métricas relacionadas à posterior avaliação do modelo. Além da apresentação e discussão, de fato, da primeira modelagem desenvolvida. \n",
    "\n",
    "\n",
    "#### Organização dos Dados\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Importadas\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pnd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listas = ['month_2.csv', 'month_3.csv', 'month_4.csv', 'month_5.csv', 'month_6.csv']\n",
    "df = []\n",
    "for arquivo in listas:\n",
    "    df += [pnd.read_csv(arquivo)]\n",
    "#Concatena todos os dataframes em um único dataframe chamado df\n",
    "df = pnd.concat(df)\n",
    "#Chama o dataframe contido na variável chamada df\n",
    "dadosCadastrais = pnd.read_csv('informacao_cadastral.csv')\n",
    "usuariosUnicos = dadosCadastrais[dadosCadastrais.situacao == 'CONSUMINDO GÁS']['clientCode'].unique() \n",
    "#Organiza os dados dos usuários filtrados pela data\n",
    "mesFiltrado = df[df['clientCode'].isin(usuariosUnicos)].sort_values(by='datetime') \n",
    "#Filtra meterSN diferente de '>N<A'\n",
    "df = mesFiltrado[mesFiltrado['meterSN'] != '>N<A']\n",
    "#Garante que todas as linhas com gain nulo sejam preenchidas com 1. Não é garantido que é o valor correto, mas é o melhor que podemos fazer\n",
    "df['gain'].fillna(1, inplace=True)\n",
    "#Corrige os pulsos para m²\n",
    "df['pulseCount'] = df['pulseCount'] * df['gain']\n",
    "#Cria a variação do pulseCount como uma coluna nova, calculando por grupo a diferença\n",
    "df['diffPulseCount'] = df.groupby(['clientCode', 'meterSN']).pulseCount.diff()\n",
    "#Preenche os valores nulos (iniciais) com 0\n",
    "df['diffPulseCount'].fillna(0, inplace=True)\n",
    "#Reseta o index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#Seleciona as colunas que serão usadas\n",
    "df = df[['clientCode', 'meterSN', \"pulseCount\", 'diffPulseCount','datetime']]\n",
    "#Calcula a média e o desvio padrão do diffPulseCount por cliente\n",
    "df['mediaCliente'] = df.groupby(['clientCode', 'meterSN']).diffPulseCount.transform('mean')\n",
    "df['desvioPadraoCliente'] = df.groupby(['clientCode', 'meterSN']).diffPulseCount.transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova coluna chamada tipo\n",
    "df['tipo'] = 0\n",
    "# Mostra o dataframe\n",
    "print(df)\n",
    "# Compara a variação do pulseCount em relação a 3 desvios padrões e define como tipo 3\n",
    "df.loc[df['diffPulseCount'] > df['mediaCliente'] + 3 * df['desvioPadraoCliente'], 'tipo'] = 3\n",
    "# Verifica se variação do pulseCount é menor que zero e define como tipo 1\n",
    "df.loc[df['diffPulseCount'] < 0, 'tipo'] = 1\n",
    "# Verifica se a variação do pulse count é igual a zero e define como tipo 2\n",
    "df.loc[(df['pulseCount'] == 0) & (df['diffPulseCount'] < 0), 'tipo'] = 2\n",
    "# Conta a frequência de cada tipo\n",
    "df.tipo.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelagem Para o Problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets for the non-supervised model\n",
    "X = df[['pulseCount', 'diffPulseCount']]\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train has the columns 'pulseCount' and 'diffPulseCount'\n",
    "L = X_train[['pulseCount', 'diffPulseCount']]\n",
    "\n",
    "# List to store SSE values\n",
    "sse = []\n",
    "\n",
    "# Range of k\n",
    "k_range = range(1, 11)\n",
    "\n",
    "# Loop through values of k\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(L)  # Fit the KMeans model to X_train data\n",
    "    sse.append(kmeans.inertia_)  # Append the SSE (inertia) for each k\n",
    "\n",
    "# Plotting the Elbow plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, sse, marker='o')\n",
    "plt.title('Elbow Plot for K-Means Clustering')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Sum of Squared Distances (SSE)')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Verify column names\n",
    "print(df.columns)\n",
    "\n",
    "# Use the same DataFrame for both clustering and plotting\n",
    "L = df[['diffPulseCount', 'pulseCount']].dropna()\n",
    "\n",
    "# Fit the KMeans model\n",
    "k = 3  # Choose the number of clusters based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(L)\n",
    "\n",
    "# Get the cluster labels and centroids\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Create scatterplot with the correct data\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(L['diffPulseCount'], L['pulseCount'], c=labels, cmap='viridis', marker='o')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75, marker='x')  # Centroids\n",
    "plt.title(f'K-Means Clustering (k={k})')\n",
    "plt.xlabel('diffPulseCount')\n",
    "plt.ylabel('pulseCount')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reset index of X_train before fitting\n",
    "X_train_reset = X_train.reset_index(drop=True)\n",
    "\n",
    "# Fit the KMeans model on the reset training data\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X_train_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Silhouette Score for Train Subset ---\n",
    "\n",
    "# Sample the data (reset the index after sampling)\n",
    "subset = X_train_reset.sample(n=500000, random_state=42)\n",
    "\n",
    "# Get the corresponding labels by predicting on the subset\n",
    "subset_labels = kmeans.predict(subset)\n",
    "\n",
    "# Calculate silhouette score on the subset\n",
    "silhouette_avg = silhouette_score(subset, subset_labels)\n",
    "print(f\"Silhouette Score (Train Subset): {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Clusters for Train Subset ---\n",
    "\n",
    "# Scatter plot for the train subset\n",
    "plt.scatter(subset['pulseCount'], subset['diffPulseCount'], c=subset_labels)\n",
    "plt.xlabel('Pulse Count')\n",
    "plt.ylabel('Δ Pulse Count')\n",
    "plt.title('K-means Clustering de Pulse Count vs Diferença em Pulse Count (Sub-Grupo de Treino)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict and Plot for Full Training Set ---\n",
    "\n",
    "# Predict labels for the full training set\n",
    "train_labels_full = kmeans.predict(X_train_reset)\n",
    "\n",
    "# Scatter plot for the full training set\n",
    "plt.scatter(X_train_reset['pulseCount'], X_train_reset['diffPulseCount'], c=train_labels_full)\n",
    "plt.xlabel('Pulse Count')\n",
    "plt.ylabel('Δ Pulse Count')\n",
    "plt.title('K-means Clustering de Pulse Count vs Diferença em Pulse Count (Grupo de Treino Completo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Silhouette Score for Test Subset ---\n",
    "\n",
    "# Reset the index of X_test to ensure alignment with the labels\n",
    "X_test_reset = X_test.reset_index(drop=True)\n",
    "\n",
    "# Sample the test data (1000 samples from X_test)\n",
    "subset_test = X_test_reset.sample(n=1000, random_state=42)\n",
    "\n",
    "# Predict the cluster labels for the test subset\n",
    "subset_test_labels = kmeans.predict(subset_test)\n",
    "\n",
    "# Calculate silhouette score on the subset of X_test\n",
    "silhouette_avg_test = silhouette_score(subset_test, subset_test_labels)\n",
    "print(f\"Silhouette Score (Test Subset): {silhouette_avg_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict and Plot for Full Test Set ---\n",
    "\n",
    "# Predict labels for the full test set\n",
    "test_labels = kmeans.predict(X_test_reset)\n",
    "\n",
    "# Scatter plot for the full test set\n",
    "plt.scatter(X_test_reset['pulseCount'], X_test_reset['diffPulseCount'], c=test_labels)\n",
    "plt.xlabel('Pulse Count')\n",
    "plt.ylabel('Δ Pulse Count')\n",
    "plt.title('K-means Clustering do Pulse Count vs Difference em Pulse Count (Grupo de Teste Completo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição das váriaveis do modelo**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;As variáveis escolhidas para compôr o modelo se refletem nas features identificadas como mais relevantes para a delimitação do padrão de consumo: a variação de Pulse Count (ΔPc) e Pulse Count. Assim, a primeira feature é o Pulse Count (Pc), que representa a contagem total de pulsos de gás em um sensor. Essa variável é a medida direta do consumo de gás e serve como a principal forma de monitorar padrões de consumo, sendo essencial para identificar comportamentos normais ou anômalos. Por exemplo, um valor extremamente baixo ou nulo pode indicar um problema no sistema ou a falta de consumo esperado, enquanto valores extremamente altos podem sinalizar picos anômalos de consumo, como um vazamento.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<sub>Figura X - gráfico do Pulse Count de um cliente qualquer</sub>\n",
    "\n",
    "</div><br>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![GraficoPCNormal.jpg](..\\documents\\extras\\GraficoPCNormal.jpg)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<sup>Fonte: Material produzido pelos autores (2024)</sup>\n",
    "\n",
    "</div>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;A segunda feature é a variação de Pulse Count (ΔPc), que representa a diferença na contagem de pulsos entre leituras consecutivas de um cliente. Essa feature reflete a variação no consumo de gás ao longo do tempo e é crítica para a detecção de mudanças bruscas no comportamento do consumo. Uma variação positiva inesperada, por exemplo, pode indicar uma anomalia como um vazamento de gás ou um erro de medição. Já uma variação negativa significativa, onde o consumo cai drasticamente para zero, pode ser normal (em casos de desligamento) ou anômala (quando há uma interrupção inesperada no consumo).\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<sub>Figura X - gráfico de variação Pulse Count de um cliente qualquer</sub>\n",
    "\n",
    "</div><br>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![GraficoVarPC.jpg](..\\documents\\extras\\GraficoVarPC.jpg)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<sup>Fonte: Material produzido pelos autores (2024)</sup>\n",
    "\n",
    "</div>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Essas duas variáveis complementam-se ao fornecer uma visão detalhada tanto do consumo acumulado quanto das variações ao longo do tempo, facilitando uma análise mais precisa dos padrões de uso de gás. Enquanto o Pulse Count (Pc) oferece uma visão geral do consumo total, a variação de Pulse Count (ΔPc) permite identificar oscilações súbitas ou anômalas entre as leituras. Portanto, essas duas variáveis escolhidas são relevantes para construir o modelo desejado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As features escolhidas para o modelo foram pulseCount e diffPulseCount, representando, respectivamente, o consumo total e a variação no consumo de gás. A escolha dessas variáveis se deve à sua relevância direta na identificação de padrões de uso de gás e potenciais anomalias, como vazamentos ou picos abruptos no consumo. O pulseCount reflete o volume total de gás consumido, fornecendo uma visão geral do comportamento do consumo, enquanto o diffPulseCount capta mudanças abruptas, permitindo identificar variações que podem indicar eventos anômalos. Essa combinação de variáveis é crucial para o objetivo de detectar padrões de consumo atípicos, o que torna o modelo mais eficiente em análises preditivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Silhouette Score\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;O silhouette score é uma forma de avaliar o quanto os clusters estão bem definidos, selecionados e separados uns dos outros. Ele mede a coesão interna dos pontos dentro de um cluster e o quanto cada ponto está distante dos demais clusters, oferecendo uma visão sobre a qualidade da segmentação. Quanto maior o valor do silhouette score (próximo de 1), melhor é a definição dos clusters, enquanto valores negativos indicam que os pontos estão em clusters errados.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;A importância do silhouette score para um modelo de agrupamento é baseado no fato de que ele ajuda a determinar se a escolha de um número específico de clusters e a distribuição dos dados faz sentido para a análise em questão. Além disso, ele serve como uma métrica quantitativa para comparar diferentes algoritmos de clustering ou parâmetros usados, permitindo que seja selecionado a configuração que melhor captura a estrutura dos dados. Isso garante uma interpretação mais precisa e útil dos grupos formados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussão Sobre os Resultados do Modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;O modelo preditivo não supervisionado, desenvolvido para analisar o consumo (pulseCount) em relação ao delta de consumo (diffPulseCount), apresentou resultados aceitáveis, com um silhouette score de 0,9462 para uma amostra de 500.000 registros. Utilizando k=3, esse valor reflete uma boa definição dos clusters, com coesão e uma clara separação entre os grupos formados. Ao aplicar o modelo no conjunto de testes, o silhouette score aumentou para 0,9530, destacando a consistência do processo de agrupamento.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Esses resultados indicam que o modelo foi eficaz em identificar padrões distintos de consumo, permitindo uma segmentação confiável dos dados. A precisão observada nos agrupamentos ressalta o potencial do modelo para apoiar decisões estratégicas, como a detecção de anomalias ou a identificação de comportamentos específicos de uso, fornecendo insights valiosos para a gestão do consumo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
