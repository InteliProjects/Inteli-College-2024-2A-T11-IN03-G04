{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega biblioteca pandas\n",
    "import pandas as pnd\n",
    "# Carrega biblioteca numpy\n",
    "import numpy as np\n",
    "# Carrega biblioteca matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Carrega biblioteca seaborn\n",
    "import seaborn as sb\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderQuotaExceeded\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena diferentes tabelas com cada mês (dados)\n",
    "# Em seguida salva todos os dados em um único DataFrame chamado df\n",
    "listas = ['month_2.csv', 'month_3.csv', 'month_4.csv', 'month_5.csv', 'month_6.csv']\n",
    "df = []\n",
    "for arquivo in listas:\n",
    "    df += [pnd.read_csv(arquivo)]\n",
    "\n",
    "# Concatena todos os dataframes em um único dataframe chamado df\n",
    "df = pnd.concat(df)\n",
    "\n",
    "# Chama o dataframe contido na variável chamada df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega e salva cadastroConsumindo como cadastroConsumindo\n",
    "dadosCadastrais = pnd.read_csv('informacao_cadastral.csv')\n",
    "\n",
    "# Chama o dataframe contido na variável dadoCadastrais\n",
    "dadosCadastrais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadastroConsumindo = cadastroConsumindo.loc[cadastroConsumindo['situacao'] == \"CONSUMINDO GÁS\"]\n",
    "\n",
    "print(cadastroConsumindo.shape[0], cadastroConsumindo.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega diferentes possibilidades para a coluna 'cidade'\n",
    "# Antes da normalização\n",
    "cadastroConsumindo['cidade'].unique()\n",
    "\n",
    "# Substituindo \"GRAVATAI\" por \"GRAVATAÍ\" na coluna \"cidade\"\n",
    "cadastroConsumindo['cidade'] = cadastroConsumindo['cidade'].replace('GRAVATAI', 'GRAVATAÍ')\n",
    "\n",
    "# Substituindo \"SAO LEOPOLDO\" por \"SÃO LEOPOLDO\" na coluna \"cidade\"\n",
    "cadastroConsumindo['cidade'] = cadastroConsumindo['cidade'].replace('SAO LEOPOLDO', 'SÃO LEOPOLDO')\n",
    "\n",
    "# Verificando entradas na coluna \"cidade\"\n",
    "cadastroConsumindo['cidade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter latitude e longitude com retry\n",
    "def obter_lat_long_cep(cep, tentativas=3, atraso=2):\n",
    "    geolocator = Nominatim(user_agent=\"geoapi_cadastro\")\n",
    "\n",
    "    for tentativa in range(tentativas):\n",
    "        try:\n",
    "            time.sleep(1)  # Respeitar a política de uso da API\n",
    "            location = geolocator.geocode(cep, timeout=10)\n",
    "            if location:\n",
    "                return location.latitude, location.longitude\n",
    "            else:\n",
    "                return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Tentativa {tentativa + 1} falhou: {e}\")\n",
    "            if tentativa < tentativas - 1:  # Não aguarda se for a última tentativa\n",
    "                time.sleep(atraso)\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Aplicar a função ao DataFrame com retry\n",
    "cadastroConsumindo['latitude'], cadastroConsumindo['longitude'] = zip(*cadastroConsumindo['cep'].apply(lambda cep: obter_lat_long_cep(cep)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadastroConsumindo['latitude'], cadastroConsumindo['longitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_altitude(lat, lon):\n",
    "    url = f'https://api.open-elevation.com/api/v1/lookup?locations={lat},{lon}'\n",
    "    \n",
    "    try:\n",
    "        # Solicitação GET para a API de altitude\n",
    "        resposta = requests.get(url)\n",
    "        if resposta.status_code == 200:\n",
    "            # Extrair a altitude da resposta JSON\n",
    "            dados = resposta.json()\n",
    "            altitude = dados['results'][0]['elevation']\n",
    "            return altitude\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao buscar altitude: {e}\")\n",
    "        return None\n",
    "\n",
    "# Aplicar a função para obter a altitude e criar uma nova coluna 'altitude'\n",
    "cadastroConsumindo['altitude'] = cadastroConsumindo.apply(lambda row: obter_altitude(row['latitude'], row['longitude']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_nans = cadastroConsumindo['altitude'].isna().sum()\n",
    "\n",
    "print(num_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nans_latitude = cadastroConsumindo[\"latitude\"].isna().sum()\n",
    "\n",
    "\n",
    "\n",
    "nans_longitude = cadastroConsumindo[\"longitude\"].isna().sum()\n",
    "\n",
    "print(nans_latitude, nans_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(cadastroConsumindo['longitude'], cadastroConsumindo['altitude'], color='blue', alpha=0.5, edgecolors='w', s=10)\n",
    "plt.title('Relação entre Longitude e Altitude')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Altitude (metros)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pnd.merge(df, cadastroConsumindo, on=['clientCode']) \n",
    "\n",
    "nans_clientCode = df[\"clientCode\"].isna().sum()\n",
    "\n",
    "print(merged_df.altitude.head(100))\n",
    "print(cadastroConsumindo.altitude.head(100))\n",
    "\n",
    "print(merged_df.shape[0])\n",
    "print(df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cadastroConsumindo.altitude.describe(),\n",
    "merged_df.altitude.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns\n",
    "\n",
    "print(df.shape[0], merged_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria a variação do pulseCount como uma coluna nova, calculando por grupo a diferença\n",
    "merged_df['diffPulseCount'] = merged_df.groupby(['clientCode', 'meterSN']).pulseCount.diff()\n",
    "#Preenche os valores nulos (iniciais) com 0\n",
    "merged_df['diffPulseCount'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.altitude.describe(), cadastroConsumindo.altitude.describe(), cadastroConsumindo.clientCode.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosProcessados = merged_df.dropna(subset=['diffPulseCount', 'altitude'])\n",
    "\n",
    "dadosProcessados.shape[0]\n",
    "merged_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_negativos = (dadosProcessados['diffPulseCount'] < 0).sum()\n",
    "\n",
    "print(f'Número de valores negativos: {num_negativos}')\n",
    "\n",
    "dadosPositivos = dadosProcessados[dadosProcessados['diffPulseCount'] >= 0]\n",
    "\n",
    "num_negativos = (dadosPositivos['diffPulseCount'] < 0).sum()\n",
    "\n",
    "print(f'Número de valores negativos: {num_negativos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "dados_scaled = scaler.fit_transform(dadosPositivos[['diffPulseCount', 'altitude']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []  # Soma dos erros quadráticos (distância dos pontos ao centróide mais próximo)\n",
    "k_values = range(1, 11)  # Testando de 1 a 10 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(dados_scaled)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Visualizando o Elbow plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, sse, 'bo-')\n",
    "plt.xlabel('Número de Clusters (k)')\n",
    "plt.ylabel('SSE (Soma dos Erros Quadráticos)')\n",
    "plt.title('Método Elbow para Escolha do k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3  # Defina o valor de k conforme a análise do gráfico acima\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "dadosPositivos['cluster'] = kmeans.fit_predict(dados_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sb.scatterplot(x='diffPulseCount', y='altitude', hue='cluster', data=dadosPositivos, palette='viridis')\n",
    "plt.xlabel('Delta Pulse Count')\n",
    "plt.ylabel('Altitude')\n",
    "plt.title('Clusters de Clientes por Variação de Pulse Count e Altitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(group):\n",
    "    Q1 = group['diffPulseCount'].quantile(0.25)\n",
    "    Q3 = group['diffPulseCount'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Marcar outliers\n",
    "    group['Outlier'] = group['diffPulseCount'].apply(\n",
    "        lambda x: 'Outlier' if x < lower_bound or x > upper_bound else 'Normal'\n",
    "    )\n",
    "    return group\n",
    "\n",
    "# Aplicar a função a cada cluster\n",
    "df_with_outliers = dadosPositivos.groupby('cluster').apply(identify_outliers)\n",
    "\n",
    "num_outliers = df_with_outliers['Outlier'].eq(\"Outlier\").sum()\n",
    "\n",
    "print(num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosProcessados2 = merged_df.dropna(subset=['diffPulseCount', 'altitude', 'latitude', 'longitude'])\n",
    "\n",
    "dadosProcessados2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_negativos2 = (dadosProcessados2['diffPulseCount'] < 0).sum()\n",
    "\n",
    "print(f'Número de valores negativos: {num_negativos2}')\n",
    "\n",
    "dadosPositivos2 = dadosProcessados2[dadosProcessados2['diffPulseCount'] >= 0]\n",
    "\n",
    "num_negativos2 = (dadosPositivos2['diffPulseCount'] < 0).sum()\n",
    "\n",
    "print(f'Número de valores negativos: {num_negativos2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combinar as variáveis (latitude e longitude)\n",
    "dadosPositivos2['coordinates'] = list(zip(dadosPositivos2['latitude'], dadosPositivos2['longitude']))\n",
    "\n",
    "# 2. Preparar os dados\n",
    "coordinates = dadosPositivos2['coordinates'].tolist()\n",
    "coordinates_df = pnd.DataFrame(coordinates, columns=['latitude', 'longitude'])\n",
    "\n",
    "# Concatenando com o delta_pulse_count\n",
    "data_for_kmeans = pnd.concat([coordinates_df, dadosPositivos2['diffPulseCount']], axis=1).dropna()\n",
    "\n",
    "print(data_for_kmeans.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []  # Soma dos erros quadráticos (distância dos pontos ao centróide mais próximo)\n",
    "k_values = range(1, 11)  # Testando de 1 a 10 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_for_kmeans)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Visualizando o Elbow plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, sse, 'bo-')\n",
    "plt.xlabel('Número de Clusters (k)')\n",
    "plt.ylabel('SSE (Soma dos Erros Quadráticos)')\n",
    "plt.title('Método Elbow para Escolha do k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test = train_test_split(data_for_kmeans, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Executar o K-means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # ajuste o número de clusters conforme necessário\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "# 5. Fazer previsões no conjunto de teste\n",
    "y_test_pred = kmeans.predict(X_test_scaled)\n",
    "\n",
    "# 6. Avaliar o modelo com silhouette score no conjunto de teste\n",
    "silhouette_avg = silhouette_score(X_test_scaled, y_test_pred)\n",
    "print(f'Silhouette Score no conjunto de teste: {silhouette_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cluster'] = kmeans.labels_\n",
    "\n",
    "X_train['latitude'].value_counts()\n",
    "X_train['longitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroides = kmeans.cluster_centers_\n",
    "\n",
    "# 2. Criar o gráfico de dispersão\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot dos dados com base nos clusters\n",
    "sb.scatterplot(x=data_for_kmeans['longitude'], \n",
    "                y=data_for_kmeans['latitude'], \n",
    "                hue=X_train['cluster'],  # Cor baseada nos clusters\n",
    "                palette='deep',      # Paleta de cores\n",
    "                s=50,                # Tamanho dos pontos\n",
    "                alpha=0.7)           # Transparência para melhor visualização\n",
    "\n",
    "# 3. Adicionar os centroides no gráfico\n",
    "plt.scatter(centroides[:, 1], centroides[:, 0],  # Longitude e Latitude dos centroides\n",
    "            c='red', \n",
    "            s=200, \n",
    "            marker='X', \n",
    "            label='Centroides')\n",
    "\n",
    "# 4. Títulos e legendas\n",
    "plt.title('Clusters de Clientes com K-means', fontsize=14)\n",
    "plt.xlabel('Longitude', fontsize=12)\n",
    "plt.ylabel('Latitude', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 5. Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Criar o gráfico de dispersão 3D\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot dos dados, com clusters em 3D\n",
    "scatter = ax.scatter(X_train['longitude'],  # eixo X\n",
    "                     X_train['latitude'],   # eixo Y\n",
    "                     X_train['diffPulseCount'], # eixo Z (delta pulse count)\n",
    "                     c=X_train['cluster'],    # Cor com base nos clusters\n",
    "                     cmap='viridis',     # Paleta de cores\n",
    "                     s=50,               # Tamanho dos pontos\n",
    "                     alpha=0.7)          # Transparência dos pontos\n",
    "\n",
    "# 4. Títulos e rótulos dos eixos\n",
    "ax.set_title('Clusters de Clientes com K-means (Longitude, Latitude e Delta Pulse Count)', fontsize=14)\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_zlabel('Delta Pulse Count', fontsize=12)\n",
    "\n",
    "# 5. Adicionar uma barra de cores para facilitar a leitura dos clusters\n",
    "cbar = fig.colorbar(scatter)\n",
    "cbar.set_label('Cluster')\n",
    "\n",
    "# 6. Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "# Calculando as distâncias entre os pontos e os centróides\n",
    "distances = pairwise_distances_argmin_min(kmeans.cluster_centers_, X_train)[1]\n",
    "\n",
    "# Definir um limiar de distância para considerar um ponto como anômalo\n",
    "threshold = 1.5 * distances.mean()  # Exemplo de limiar\n",
    "anomalias = distances > threshold\n",
    "\n",
    "print(\"Número de anomalias detectadas:\", sum(anomalias))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
